{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcXfxEieXAIl"
   },
   "source": [
    "# CNN Model for MNIST Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5753,
     "status": "ok",
     "timestamp": 1590600216102,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "i3HiqylaUbhE",
    "outputId": "5a6439d4-d9e7-4a2c-ea29-ee0a5ca42164"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwL7Wk4OUrda"
   },
   "outputs": [],
   "source": [
    "''' Build a simple MNIST classification CNN\n",
    "    The network takes ~3 minutes to train on a normal laptop and reaches roughly 97% of accuracy\n",
    "    Model structure: Conv, Conv, Max pooling, Dropout, Dense, Dense\n",
    "'''\n",
    "def build_mnist_model():\n",
    "    \n",
    "    activation = 'relu'\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols, img_colors = 28, 28, 1\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(8, kernel_size=(3, 3), input_shape=(img_rows, img_cols, img_colors), activation=activation))\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation=activation))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=activation))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    model.add(layers.Activation('softmax', name='y_pred'))\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06a_kb5dU8Z-"
   },
   "outputs": [],
   "source": [
    "''' Normalize input to the range of [0..1]\n",
    "    Apart from assisting in the convergance of the training process, this \n",
    "    will also make our lives easier during the adversarial attack process\n",
    "'''\n",
    "def normalize(x_train,x_test):\n",
    "    x_train -= x_train.min()\n",
    "    x_train /= x_train.max()\n",
    "    x_test -= x_test.min()\n",
    "    x_test /= x_test.max()\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtXiH7ueUuJ2"
   },
   "outputs": [],
   "source": [
    "# Load and prepare the datasets for training\n",
    "num_classes = 10\n",
    "\n",
    "img_rows, img_cols, img_colors = 28, 28, 1\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "train_images, test_images = normalize(train_images, test_images)\n",
    "sanity_images = test_images[:10]\n",
    "    \n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "sanity_labels = test_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 337952,
     "status": "ok",
     "timestamp": 1590600550218,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "4VjTmAGLU2CB",
    "outputId": "760b41ac-8171-4db4-e3c3-4024c1d03365"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0531 15:04:57.543425 4710012352 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 1.0247 - categorical_accuracy: 0.6712 - val_loss: 0.3015 - val_categorical_accuracy: 0.9204\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 14s 228us/sample - loss: 0.4442 - categorical_accuracy: 0.8639 - val_loss: 0.2275 - val_categorical_accuracy: 0.9378\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 0.3612 - categorical_accuracy: 0.8911 - val_loss: 0.1884 - val_categorical_accuracy: 0.9477\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 13s 225us/sample - loss: 0.3137 - categorical_accuracy: 0.9047 - val_loss: 0.1589 - val_categorical_accuracy: 0.9553\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 14s 228us/sample - loss: 0.2727 - categorical_accuracy: 0.9177 - val_loss: 0.1387 - val_categorical_accuracy: 0.9595\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 14s 237us/sample - loss: 0.2463 - categorical_accuracy: 0.9261 - val_loss: 0.1247 - val_categorical_accuracy: 0.9634\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 14s 234us/sample - loss: 0.2279 - categorical_accuracy: 0.9320 - val_loss: 0.1125 - val_categorical_accuracy: 0.9665\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 14s 226us/sample - loss: 0.2118 - categorical_accuracy: 0.9373 - val_loss: 0.1047 - val_categorical_accuracy: 0.9685\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 0.1929 - categorical_accuracy: 0.9414 - val_loss: 0.0961 - val_categorical_accuracy: 0.9712\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 14s 225us/sample - loss: 0.1856 - categorical_accuracy: 0.9453 - val_loss: 0.0901 - val_categorical_accuracy: 0.9724\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 14s 225us/sample - loss: 0.1763 - categorical_accuracy: 0.9466 - val_loss: 0.0852 - val_categorical_accuracy: 0.9743\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 14s 231us/sample - loss: 0.1674 - categorical_accuracy: 0.9506 - val_loss: 0.0804 - val_categorical_accuracy: 0.9754\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 128\n",
    "maxepoches = 12\n",
    "learning_rate = 0.1\n",
    "lr_decay = 1e-6\n",
    "lr_drop = 20\n",
    "\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "model = build_mnist_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=maxepoches,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZX91Mu6XNDZ"
   },
   "source": [
    "# Attack Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCnTbDAfXSn7"
   },
   "outputs": [],
   "source": [
    "''' A simple utility funcion for evaluating the success of an attack\n",
    "'''\n",
    "def TestAttack(model, adv_images, orig_images, true_labels, target_labels=None, targeted=False):\n",
    "    score = model.evaluate(adv_images, true_labels, verbose=0)\n",
    "    print('Test loss: {:.2f}'.format(score[0]))\n",
    "    print('Successfully moved out of source class: {:.2f}'.format( 1 - score[1]))\n",
    "    \n",
    "    if targeted:\n",
    "        score = model.evaluate(adv_images, target_labels, verbose=0)\n",
    "        print('Test loss: {:.2f}'.format(score[0]))\n",
    "        print('Successfully perturbed to target class: {:.2f}'.format(score[1]))\n",
    "    \n",
    "    dist = np.mean(np.sqrt(np.mean(np.square(adv_images - orig_images), axis=(1,2,3))))\n",
    "    print('Mean perturbation distance: {:.2f}'.format(dist))\n",
    "    \n",
    "    index = 3\n",
    "    img = adv_images[index].reshape(28, 28)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    ret_score = score[1] if targeted else 1 - score[1]\n",
    "    return ret_score, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4CY5x0qXYkW"
   },
   "source": [
    "# Part I - TF Implementation for PGD Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IoNpZ9V2XnPx"
   },
   "source": [
    "## 1. FGSM and TGSM implementations against the MNIST testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2CpRwsZXT_s"
   },
   "outputs": [],
   "source": [
    "''' Fast Gradient Sign Method implementation - perturb all input features by an epsilon sized step in \n",
    "    the direction of loss gradient\n",
    "'''\n",
    "def FGSM(model, images, labels, epsilon=0.3):\n",
    "    # define fgsm model session\n",
    "    adv_loss = keras.losses.categorical_crossentropy(labels, model.output)\n",
    "    grads_wrt_input = keras.backend.gradients(adv_loss, model.input)[0]\n",
    "    sign_grads = keras.backend.sign(grads_wrt_input)\n",
    "    delta = epsilon * sign_grads\n",
    "    images_adv  = images + delta\n",
    "\n",
    "    # run session\n",
    "    sess = keras.backend.get_session()\n",
    "    adv_out = sess.run(images_adv, feed_dict={model.input: images})\n",
    "    \n",
    "    return adv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrcFhGeoyUfy"
   },
   "outputs": [],
   "source": [
    "images_adv = FGSM(model, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 369436,
     "status": "ok",
     "timestamp": 1590600052637,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "8yhZjxB513R6",
    "outputId": "51f5ac20-b012-4d4f-fbfc-445ad91be5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.26\n",
      "Successfully moved out of source class: 0.97\n",
      "Mean perturbation distance: 0.29\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute perturbations using FGSM\n",
    "adv_images = FGSM(model, test_images, test_labels, epsilon=0.3)\n",
    "TestAttack(model, adv_images, test_images, test_labels, targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Fjt2-I1-BJ"
   },
   "outputs": [],
   "source": [
    "''' Targeted Gradient Sign Method implementation - A targeted variant of the FGSM attack\n",
    "    here we minimize the loss with respect to the target class, as opposed to maximizing the loss with respect\n",
    "    to the source class\n",
    "'''\n",
    "def TGSM(model, images, target, epsilon=0.3):\n",
    "    # define fgsm model session\n",
    "    adv_loss = keras.losses.categorical_crossentropy(target, model.output)\n",
    "    grads_wrt_input = keras.backend.gradients(adv_loss, model.input)[0]\n",
    "    sign_grads = keras.backend.sign(grads_wrt_input)\n",
    "    delta = epsilon * sign_grads\n",
    "    images_adv  = images - delta\n",
    "\n",
    "    # run session\n",
    "    sess = keras.backend.get_session()\n",
    "    adv_out = sess.run(images_adv, feed_dict={model.input: images})\n",
    "    \n",
    "    return adv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 376694,
     "status": "ok",
     "timestamp": 1590600059917,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "CfBKM6qE2s30",
    "outputId": "ca0885e6-0478-4e8d-e319-197eb49cd314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.18\n",
      "Successfully moved out of source class: 0.94\n",
      "Test loss: 1.05\n",
      "Successfully perturbed to target class: 0.62\n",
      "Mean perturbation distance: 0.29\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose random target classes per each instance in the test set\n",
    "target = (np.argmax(test_labels, axis=1) + np.random.randint(1, num_classes, size=(test_labels.shape[0]))) % num_classes\n",
    "target = keras.utils.to_categorical(target, num_classes)\n",
    "\n",
    "# Compute perturbations using TGSM\n",
    "adv_images = TGSM(model, test_images, target, epsilon=0.3)\n",
    "TestAttack(model, adv_images, test_images, test_labels, target, targeted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5W2pWgo_4Y0V"
   },
   "source": [
    "## 2. PGD Implementation\n",
    "\n",
    "\n",
    "*   Perform projection step only when exceeding allowed radius\n",
    "*   Different constants for overall perturbation distance and iteration step size\n",
    "*   Support for targeted and untargerted\n",
    "*   Clipping to allowed values (0,1)\n",
    "*   Numerical stability (no zero division)\n",
    "*   Batch attacks in a single call\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxyGbD5q4a1H"
   },
   "outputs": [],
   "source": [
    "def PGD(model, images, labels, epsilon=0.1, iter_eps=0.05, iterations=10, min_x=0.0, max_x=1.0, targeted=False):\n",
    "    # initialization\n",
    "    x = images  # batch attacks \n",
    "    stability = 1e-11\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        print(f\"iteration: {i+1}\")\n",
    "        if targeted:  # support for targeted and untargeted\n",
    "            x = TGSM(model, x, labels, iter_eps)\n",
    "        else:\n",
    "            x = FGSM(model, x, labels, iter_eps)\n",
    "\n",
    "        # calculate delta and norm\n",
    "        delta = x - images\n",
    "        norm = tf.norm(delta, ord='euclidean', axis=[1,2])  # norm always >= 0\n",
    "        stable_norm = norm + stability  # assure numerical stability\n",
    "\n",
    "        # reshape to divide all images by norm\n",
    "        orig_delta_shape = tf.shape(delta)  # keep for reshaping back\n",
    "        delta = tf.reshape(delta, shape=[orig_delta_shape[0], -1,])\n",
    "\n",
    "        # only project where exceeds epsilon radius\n",
    "        projection_mask = norm > epsilon\n",
    "        dimension = tf.shape(delta)[-1]\n",
    "        expanded_mask = keras.backend.repeat(projection_mask, dimension)\n",
    "        expanded_mask = tf.reshape(expanded_mask, [-1, dimension])\n",
    "        delta = tf.where(expanded_mask, delta / stable_norm, delta)\n",
    "        delta = tf.reshape(delta, shape=orig_delta_shape)\n",
    "        x += delta\n",
    "        x = tf.clip_by_value(x, min_x, max_x)  # clip to allowed range\n",
    "\n",
    "        sess = keras.backend.get_session()\n",
    "        x = sess.run(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5_OocIo3TFc"
   },
   "source": [
    "## 3. Test PGD implementation over MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JwtgwWs2Rgf"
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels,\n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment #1\n",
      "iteration: 1\n",
      "iteration: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-729bb8cfea4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtargeted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0madv_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-117-55a2bf3c86e7>\u001b[0m in \u001b[0;36mPGD\u001b[0;34m(model, images, labels, epsilon, iter_eps, iterations, min_x, max_x, targeted)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTGSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFGSM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# calculate delta and norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bf4320cb3487>\u001b[0m in \u001b[0;36mFGSM\u001b[0;34m(model, images, labels, epsilon)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# run session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0madv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madv_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1341\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i, experiment in enumerate(experiments):\n",
    "    print(f\"Experiment #{i+1}\")\n",
    "    adv_images = PGD(model, test_images, **experiment)\n",
    "    ex_score = TestAttack(model, adv_images, test_images, test_labels, target, targeted=experiment['targeted'])\n",
    "    scores.append(ex_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "Test loss: 0.31\n",
      "Successfully moved out of source class: 0.10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 10000 input samples and 10 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-01d985581d32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPGD2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargeted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-109-05ff9563857b>\u001b[0m in \u001b[0;36mPGD2\u001b[0;34m(model, images, labels, epsilon, iter_eps, iterations, min_x, max_x, targeted, restrict_frame, restrict_black)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mTestAttack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanity_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargeted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-ceda2ae96ff5>\u001b[0m in \u001b[0;36mTestAttack\u001b[0;34m(model, adv_images, orig_images, true_labels, target_labels, targeted)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtargeted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Successfully perturbed to target class: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2686\u001b[0m       \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m         \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    481\u001b[0m                      \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                      \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                      'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 10000 input samples and 10 target samples."
     ]
    }
   ],
   "source": [
    "PGD2(model, test_images, test_labels, iterations=30, epsilon=3, iter_eps=0.03, targeted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guGyFnoQGA8k"
   },
   "source": [
    "# Part II - Beyond GPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_mask(tensor):\n",
    "    \"\"\"\n",
    "    A utility function that returns a frame numpy array\n",
    "    given two dimensions, where the frame pixels are of value 0\n",
    "    and non-frame pixels are of value 1\n",
    "    \"\"\"\n",
    "    shape = tensor.shape\n",
    "    frame = np.ones((shape[1], shape[2]), dtype=tensor.dtype)\n",
    "    frame[0, :] = 0\n",
    "    frame[shape[1] - 1, :] = 0\n",
    "    frame[:, 0] = 0\n",
    "    frame[:, shape[2] - 1] = 0\n",
    "    frame = np.tile(frame, (shape[0], 1, 1))\n",
    "    frame = np.expand_dims(frame, axis=-1)  # return to original shape\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_mask(tensor):\n",
    "    \"\"\"\n",
    "    A utility function that returns a mask numpy array\n",
    "    given a tensor, where the black pixels are of value 0\n",
    "    and non-black pixels are of value 1\n",
    "    \"\"\"\n",
    "    return (tensor != 0).astype(tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmWiIesGGCjo"
   },
   "outputs": [],
   "source": [
    "def PGD2(model, images, labels, epsilon=0.1, iter_eps=0.05, iterations=10, min_x=0.0, max_x=1.0, targeted=False,\n",
    "         restrict_frame=False, restrict_black=False):\n",
    "    # initialization\n",
    "    x = images  # batch attacks \n",
    "    stability = 1e-11\n",
    "\n",
    "    if restrict_frame:\n",
    "        frame_mask = tf.constant(get_frame_mask(images))\n",
    "        \n",
    "    if restrict_black:\n",
    "        black_mask = tf.constant(get_black_mask(images))\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        print(f\"iteration: {i+1}\")\n",
    "        if targeted:  # support for targeted and untargeted\n",
    "            x = TGSM(model, x, labels, iter_eps)\n",
    "        else:\n",
    "            x = FGSM(model, x, labels, iter_eps)\n",
    "\n",
    "        # calculate delta and norm\n",
    "        delta = x - images\n",
    "        norm = tf.norm(delta, ord='euclidean', axis=[1,2])  # norm always >= 0\n",
    "        stable_norm = norm + stability  # assure numerical stability\n",
    "\n",
    "        # reshape to divide all images by norm\n",
    "        orig_delta_shape = tf.shape(delta)  # keep for reshaping back\n",
    "        delta = tf.reshape(delta, shape=[orig_delta_shape[0], -1,])\n",
    "\n",
    "        # only project where exceeds epsilon radius\n",
    "        projection_mask = norm > epsilon\n",
    "        dimension = tf.shape(delta)[-1]\n",
    "        expanded_mask = keras.backend.repeat(projection_mask, dimension)\n",
    "        expanded_mask = tf.reshape(expanded_mask, [-1, dimension])\n",
    "        delta = tf.where(expanded_mask, delta / stable_norm, delta)\n",
    "        delta = tf.reshape(delta, shape=orig_delta_shape)\n",
    "\n",
    "        # restrict certain parts of the image\n",
    "        if restrict_frame:\n",
    "            delta = delta * frame_mask   \n",
    "        if restrict_black:\n",
    "            delta = delta * black_mask\n",
    "            \n",
    "        x += delta\n",
    "        x = tf.clip_by_value(x, min_x, max_x)  # clip to allowed range\n",
    "\n",
    "        sess = keras.backend.get_session()\n",
    "        x = sess.run(x)\n",
    "        \n",
    "        TestAttack(model, x, images, labels, sanity_target, targeted=True)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_experiments = [\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels,\n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_experiments = [\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels,\n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frmae_scores = []\n",
    "for i, frame_experiment in enumerate(experiments):\n",
    "    print(f\"Experiment #{i+1}\")\n",
    "    adv_images = PGD(model, test_images, **experiment)\n",
    "    ex_score = TestAttack(model, adv_images, test_images, test_labels, target, targeted=experiment['targeted'])\n",
    "    frmae_scores.append(ex_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blac_scores = []\n",
    "for i, black_experiment in enumerate(experiments):\n",
    "    print(f\"Experiment #{i+1}\")\n",
    "    adv_images = PGD(model, test_images, **experiment)\n",
    "    ex_score = TestAttack(model, adv_images, test_images, test_labels, target, targeted=experiment['targeted'])\n",
    "    black.append(ex_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzkZ6GhmZoMT3aWbV8Acdp",
   "collapsed_sections": [],
   "name": "adversarial_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
