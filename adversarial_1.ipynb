{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcXfxEieXAIl"
   },
   "source": [
    "# CNN Model for MNIST Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5753,
     "status": "ok",
     "timestamp": 1590600216102,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "i3HiqylaUbhE",
    "outputId": "5a6439d4-d9e7-4a2c-ea29-ee0a5ca42164"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwL7Wk4OUrda"
   },
   "outputs": [],
   "source": [
    "''' Build a simple MNIST classification CNN\n",
    "    The network takes ~3 minutes to train on a normal laptop and reaches roughly 97% of accuracy\n",
    "    Model structure: Conv, Conv, Max pooling, Dropout, Dense, Dense\n",
    "'''\n",
    "def build_mnist_model():\n",
    "    \n",
    "    activation = 'relu'\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols, img_colors = 28, 28, 1\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(8, kernel_size=(3, 3), input_shape=(img_rows, img_cols, img_colors), activation=activation))\n",
    "    model.add(layers.Conv2D(8, (3, 3), activation=activation))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=activation))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    model.add(layers.Activation('softmax', name='y_pred'))\n",
    "              \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06a_kb5dU8Z-"
   },
   "outputs": [],
   "source": [
    "''' Normalize input to the range of [0..1]\n",
    "    Apart from assisting in the convergance of the training process, this \n",
    "    will also make our lives easier during the adversarial attack process\n",
    "'''\n",
    "def normalize(x_train,x_test):\n",
    "    x_train -= x_train.min()\n",
    "    x_train /= x_train.max()\n",
    "    x_test -= x_test.min()\n",
    "    x_test /= x_test.max()\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtXiH7ueUuJ2"
   },
   "outputs": [],
   "source": [
    "# Load and prepare the datasets for training\n",
    "num_classes = 10\n",
    "\n",
    "img_rows, img_cols, img_colors = 28, 28, 1\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "train_images, test_images = normalize(train_images, test_images)\n",
    "sanity_images = test_images[:10]\n",
    "    \n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "sanity_labels = test_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 337952,
     "status": "ok",
     "timestamp": 1590600550218,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "4VjTmAGLU2CB",
    "outputId": "760b41ac-8171-4db4-e3c3-4024c1d03365"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 128\n",
    "maxepoches = 12\n",
    "learning_rate = 0.1\n",
    "lr_decay = 1e-6\n",
    "lr_drop = 20\n",
    "\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "model = build_mnist_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=maxepoches,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZX91Mu6XNDZ"
   },
   "source": [
    "# Attack Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCnTbDAfXSn7"
   },
   "outputs": [],
   "source": [
    "''' A simple utility funcion for evaluating the success of an attack\n",
    "'''\n",
    "def TestAttack(model, adv_images, orig_images, true_labels, target_labels=None, targeted=False):\n",
    "    score = model.evaluate(adv_images, true_labels, verbose=0)\n",
    "    print('Test loss: {:.2f}'.format(score[0]))\n",
    "    print('Successfully moved out of source class: {:.2f}'.format( 1 - score[1]))\n",
    "    \n",
    "    if targeted:\n",
    "        score = model.evaluate(adv_images, target_labels, verbose=0)\n",
    "        print('Test loss: {:.2f}'.format(score[0]))\n",
    "        print('Successfully perturbed to target class: {:.2f}'.format(score[1]))\n",
    "    \n",
    "    dist = np.mean(np.sqrt(np.mean(np.square(adv_images - orig_images), axis=(1,2,3))))\n",
    "    print('Mean perturbation distance: {:.2f}'.format(dist))\n",
    "    \n",
    "    index = 3\n",
    "    img = adv_images[index].reshape(28, 28)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    ret_score = score[1] if targeted else 1 - score[1]\n",
    "    return ret_score, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4CY5x0qXYkW"
   },
   "source": [
    "# Part I - TF Implementation for PGD Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IoNpZ9V2XnPx"
   },
   "source": [
    "## 1. FGSM and TGSM implementations against the MNIST testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2CpRwsZXT_s"
   },
   "outputs": [],
   "source": [
    "''' Fast Gradient Sign Method implementation - perturb all input features by an epsilon sized step in \n",
    "    the direction of loss gradient\n",
    "'''\n",
    "def FGSM(model, images, labels, epsilon=0.3):\n",
    "    # define fgsm model session\n",
    "    adv_loss = keras.losses.categorical_crossentropy(labels, model.output)\n",
    "    grads_wrt_input = keras.backend.gradients(adv_loss, model.input)[0]\n",
    "    sign_grads = keras.backend.sign(grads_wrt_input)\n",
    "    delta = epsilon * sign_grads\n",
    "    images_adv  = images + delta\n",
    "\n",
    "    # run session\n",
    "    sess = keras.backend.get_session()\n",
    "    adv_out = sess.run(images_adv, feed_dict={model.input: images})\n",
    "    \n",
    "    return adv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrcFhGeoyUfy"
   },
   "outputs": [],
   "source": [
    "images_adv = FGSM(model, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 369436,
     "status": "ok",
     "timestamp": 1590600052637,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "8yhZjxB513R6",
    "outputId": "51f5ac20-b012-4d4f-fbfc-445ad91be5f4"
   },
   "outputs": [],
   "source": [
    "# Compute perturbations using FGSM\n",
    "adv_images = FGSM(model, test_images, test_labels, epsilon=0.3)\n",
    "TestAttack(model, adv_images, test_images, test_labels, targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Fjt2-I1-BJ"
   },
   "outputs": [],
   "source": [
    "''' Targeted Gradient Sign Method implementation - A targeted variant of the FGSM attack\n",
    "    here we minimize the loss with respect to the target class, as opposed to maximizing the loss with respect\n",
    "    to the source class\n",
    "'''\n",
    "def TGSM(model, images, target, epsilon=0.3):\n",
    "    # define fgsm model session\n",
    "    adv_loss = keras.losses.categorical_crossentropy(target, model.output)\n",
    "    grads_wrt_input = keras.backend.gradients(adv_loss, model.input)[0]\n",
    "    sign_grads = keras.backend.sign(grads_wrt_input)\n",
    "    delta = epsilon * sign_grads\n",
    "    images_adv  = images - delta\n",
    "\n",
    "    # run session\n",
    "    sess = keras.backend.get_session()\n",
    "    adv_out = sess.run(images_adv, feed_dict={model.input: images})\n",
    "    \n",
    "    return adv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 376694,
     "status": "ok",
     "timestamp": 1590600059917,
     "user": {
      "displayName": "Ido Calman",
      "photoUrl": "",
      "userId": "08425851212466799066"
     },
     "user_tz": -180
    },
    "id": "CfBKM6qE2s30",
    "outputId": "ca0885e6-0478-4e8d-e319-197eb49cd314"
   },
   "outputs": [],
   "source": [
    "# Choose random target classes per each instance in the test set\n",
    "target = (np.argmax(test_labels, axis=1) + np.random.randint(1, num_classes, size=(test_labels.shape[0]))) % num_classes\n",
    "target = keras.utils.to_categorical(target, num_classes)\n",
    "\n",
    "# Compute perturbations using TGSM\n",
    "adv_images = TGSM(model, test_images, target, epsilon=0.3)\n",
    "TestAttack(model, adv_images, test_images, test_labels, target, targeted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5W2pWgo_4Y0V"
   },
   "source": [
    "## 2. PGD Implementation\n",
    "\n",
    "\n",
    "*   Perform projection step only when exceeding allowed radius\n",
    "*   Different constants for overall perturbation distance and iteration step size\n",
    "*   Support for targeted and untargerted\n",
    "*   Clipping to allowed values (0,1)\n",
    "*   Numerical stability (no zero division)\n",
    "*   Batch attacks in a single call\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxyGbD5q4a1H"
   },
   "outputs": [],
   "source": [
    "def PGD(model, images, labels, epsilon=0.1, iter_eps=0.05, iterations=10, min_x=0.0, max_x=1.0, targeted=False):\n",
    "    # initialization\n",
    "    x = images  # batch attacks \n",
    "    stability = 1e-11\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        print(f\"iteration: {i+1}\")\n",
    "        if targeted:  # support for targeted and untargeted\n",
    "            x = TGSM(model, x, labels, iter_eps)\n",
    "        else:\n",
    "            x = FGSM(model, x, labels, iter_eps)\n",
    "\n",
    "        # calculate delta and norm\n",
    "        delta = x - images\n",
    "        norm = tf.norm(delta, ord='euclidean', axis=[1,2])  # norm always >= 0\n",
    "        stable_norm = norm + stability  # assure numerical stability\n",
    "\n",
    "        # reshape to divide all images by norm\n",
    "        orig_delta_shape = tf.shape(delta)  # keep for reshaping back\n",
    "        delta = tf.reshape(delta, shape=[orig_delta_shape[0], -1,])\n",
    "\n",
    "        # only project where exceeds epsilon radius\n",
    "        projection_mask = norm > epsilon\n",
    "        dimension = tf.shape(delta)[-1]\n",
    "        expanded_mask = keras.backend.repeat(projection_mask, dimension)\n",
    "        expanded_mask = tf.reshape(expanded_mask, [-1, dimension])\n",
    "        delta = tf.where(expanded_mask, delta / stable_norm, delta)\n",
    "        delta = tf.reshape(delta, shape=orig_delta_shape)\n",
    "        x += delta\n",
    "        x = tf.clip_by_value(x, min_x, max_x)  # clip to allowed range\n",
    "\n",
    "        sess = keras.backend.get_session()\n",
    "        x = sess.run(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5_OocIo3TFc"
   },
   "source": [
    "## 3. Test PGD implementation over MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JwtgwWs2Rgf"
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels,\n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i, experiment in enumerate(experiments):\n",
    "    print(f\"Experiment #{i+1}\")\n",
    "    adv_images = PGD(model, test_images, **experiment)\n",
    "    ex_score = TestAttack(model, adv_images, test_images, test_labels, target, targeted=experiment['targeted'])\n",
    "    scores.append(ex_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PGD2(model, test_images, test_labels, iterations=30, epsilon=3, iter_eps=0.03, targeted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guGyFnoQGA8k"
   },
   "source": [
    "# Part II - Beyond GPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_mask(tensor):\n",
    "    \"\"\"\n",
    "    A utility function that returns a frame numpy array\n",
    "    given two dimensions, where the frame pixels are of value 0\n",
    "    and non-frame pixels are of value 1\n",
    "    \"\"\"\n",
    "    shape = tensor.shape\n",
    "    frame = np.ones((shape[1], shape[2]), dtype=tensor.dtype)\n",
    "    frame[0, :] = 0\n",
    "    frame[shape[1] - 1, :] = 0\n",
    "    frame[:, 0] = 0\n",
    "    frame[:, shape[2] - 1] = 0\n",
    "    frame = np.tile(frame, (shape[0], 1, 1))\n",
    "    frame = np.expand_dims(frame, axis=-1)  # return to original shape\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_mask(tensor):\n",
    "    \"\"\"\n",
    "    A utility function that returns a mask numpy array\n",
    "    given a tensor, where the black pixels are of value 0\n",
    "    and non-black pixels are of value 1\n",
    "    \"\"\"\n",
    "    return (tensor != 0).astype(tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmWiIesGGCjo"
   },
   "outputs": [],
   "source": [
    "def PGD2(model, images, labels, epsilon=0.1, iter_eps=0.05, iterations=10, min_x=0.0, max_x=1.0, targeted=False,\n",
    "         restrict_frame=False, restrict_black=False):\n",
    "    # initialization\n",
    "    x = images  # batch attacks \n",
    "    stability = 1e-11\n",
    "\n",
    "    if restrict_frame:\n",
    "        frame_mask = tf.constant(get_frame_mask(images))\n",
    "        \n",
    "    if restrict_black:\n",
    "        black_mask = tf.constant(get_black_mask(images))\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        print(f\"iteration: {i+1}\")\n",
    "        if targeted:  # support for targeted and untargeted\n",
    "            x = TGSM(model, x, labels, iter_eps)\n",
    "        else:\n",
    "            x = FGSM(model, x, labels, iter_eps)\n",
    "\n",
    "        # calculate delta and norm\n",
    "        delta = x - images\n",
    "        norm = tf.norm(delta, ord='euclidean', axis=[1,2])  # norm always >= 0\n",
    "        stable_norm = norm + stability  # assure numerical stability\n",
    "\n",
    "        # reshape to divide all images by norm\n",
    "        orig_delta_shape = tf.shape(delta)  # keep for reshaping back\n",
    "        delta = tf.reshape(delta, shape=[orig_delta_shape[0], -1,])\n",
    "\n",
    "        # only project where exceeds epsilon radius\n",
    "        projection_mask = norm > epsilon\n",
    "        dimension = tf.shape(delta)[-1]\n",
    "        expanded_mask = keras.backend.repeat(projection_mask, dimension)\n",
    "        expanded_mask = tf.reshape(expanded_mask, [-1, dimension])\n",
    "        delta = tf.where(expanded_mask, delta / stable_norm, delta)\n",
    "        delta = tf.reshape(delta, shape=orig_delta_shape)\n",
    "\n",
    "        # restrict certain parts of the image\n",
    "        if restrict_frame:\n",
    "            delta = delta * frame_mask   \n",
    "        if restrict_black:\n",
    "            delta = delta * black_mask\n",
    "            \n",
    "        x += delta\n",
    "        x = tf.clip_by_value(x, min_x, max_x)  # clip to allowed range\n",
    "\n",
    "        sess = keras.backend.get_session()\n",
    "        x = sess.run(x)\n",
    "        \n",
    "        TestAttack(model, x, images, labels, sanity_target, targeted=True)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_experiments = [\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels,\n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': True,\n",
    "    'restricted_black': False\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_experiments = [\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': test_labels,\n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': False,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 4.0, \n",
    "    'iter_eps': 0.05, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 30, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  },\n",
    "  {\n",
    "    'labels': target, \n",
    "    'iterations': 60, \n",
    "    'epsilon': 3.0, \n",
    "    'iter_eps': 0.03, \n",
    "    'targeted': True,\n",
    "    'restricted_frame': False,\n",
    "    'restricted_black': True\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_scores = []\n",
    "for i, frame_experiment in enumerate(experiments):\n",
    "    print(f\"Experiment #{i+1}\")\n",
    "    adv_images = PGD(model, test_images, **experiment)\n",
    "    ex_score = TestAttack(model, adv_images, test_images, test_labels, target, targeted=experiment['targeted'])\n",
    "    frame_scores.append(ex_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_scores = []\n",
    "for i, black_experiment in enumerate(experiments):\n",
    "    print(f\"Experiment #{i+1}\")\n",
    "    adv_images = PGD(model, test_images, **experiment)\n",
    "    ex_score = TestAttack(model, adv_images, test_images, test_labels, target, targeted=experiment['targeted'])\n",
    "    black_scores.append(ex_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNzkZ6GhmZoMT3aWbV8Acdp",
   "collapsed_sections": [],
   "name": "adversarial_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
